{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataset is in a CSV file named 'dataset.csv'\n",
    "df = pd.read_csv('D:/Git Clones/EduQuest/learning/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded Dataset:\n",
      "  Proficiency level                    Preferred subjects  \\\n",
      "0               Low     Network and System Administration   \n",
      "1               Low  Software Engineering and Development   \n",
      "2               Low        Devops and Systems Integration   \n",
      "3               Low                   Database Management   \n",
      "4               Low     Network and System Administration   \n",
      "\n",
      "  Preferred study times       Goals  Quiz scores  Completion rates  \\\n",
      "0               Morning  Short-term            1                 1   \n",
      "1               Morning  Short-term            1                 2   \n",
      "2               Morning  Short-term            1                 3   \n",
      "3               Morning  Short-term            1                 4   \n",
      "4               Morning  Short-term            1                 5   \n",
      "\n",
      "   Time spent on different types of content Curriculum structure  \\\n",
      "0                                         1                 Exam   \n",
      "1                                         2            Knowledge   \n",
      "2                                         3                 Exam   \n",
      "3                                         4            Knowledge   \n",
      "4                                         5                 Exam   \n",
      "\n",
      "  Available content  External factors Learning style  Proficiency level_en  \\\n",
      "0          Lectures  Time Constraints         Visual                     1   \n",
      "1              Quiz  Time Constraints         Visual                     1   \n",
      "2              Quiz  Time Constraints         Visual                     1   \n",
      "3              Quiz  Time Constraints         Visual                     1   \n",
      "4              Quiz  Time Constraints         Visual                     1   \n",
      "\n",
      "   Preferred subjects_en  Preferred study times_en  Goals_en  \\\n",
      "0                      7                         3         1   \n",
      "1                      8                         3         1   \n",
      "2                      5                         3         1   \n",
      "3                      4                         3         1   \n",
      "4                      7                         3         1   \n",
      "\n",
      "   Curriculum structure_en  Available content_en  External factors_en  \n",
      "0                        0                     2                    0  \n",
      "1                        1                     3                    0  \n",
      "2                        0                     3                    0  \n",
      "3                        1                     3                    0  \n",
      "4                        0                     3                    0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the columns to be encoded\n",
    "categorical_cols = ['Proficiency level', 'Preferred subjects', 'Preferred study times', \n",
    "                    'Goals', 'Curriculum structure', 'Available content', 'External factors']\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoders_X = {}\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in categorical_cols:\n",
    "    label_encoders_X[col] = LabelEncoder()\n",
    "    df[col + '_en'] = label_encoders_X[col].fit_transform(df[col])\n",
    "\n",
    "# Display the first few rows of the dataset with encoded variables\n",
    "print(\"\\nEncoded Dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Now, label_encoders_X dictionary will contain LabelEncoder objects for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "selected_columns = ['Proficiency level_en', 'Preferred subjects_en', 'Preferred study times_en', 'Goals_en', 'Curriculum structure_en', 'External factors_en', 'Available content_en', 'Time spent on different types of content', 'Completion rates', 'Quiz scores']\n",
    "X = df[selected_columns]\n",
    "y = df['Learning style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode target variable using LabelEncoder\n",
    "label_encoder_Y = LabelEncoder()\n",
    "y = label_encoder_Y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kavin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    # Input layer with 10 nodes\n",
    "    Dense(128, activation='relu', input_shape=(10,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    # Output layer with appropriate activation function\n",
    "    Dense(3, activation='softmax')  # Assuming 3 classes for the output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer labels\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,859</span> (38.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,859\u001b[0m (38.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,859</span> (38.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,859\u001b[0m (38.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.7710 - loss: 3.1223 - val_accuracy: 0.9212 - val_loss: 0.3771\n",
      "Epoch 2/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7883 - loss: 0.8893 - val_accuracy: 0.9212 - val_loss: 0.5301\n",
      "Epoch 3/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8401 - loss: 0.7023 - val_accuracy: 0.9212 - val_loss: 0.5542\n",
      "Epoch 4/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8565 - loss: 0.5770 - val_accuracy: 0.9212 - val_loss: 0.4548\n",
      "Epoch 5/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8798 - loss: 0.5037 - val_accuracy: 0.9212 - val_loss: 0.4395\n",
      "Epoch 6/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8862 - loss: 0.4894 - val_accuracy: 0.9212 - val_loss: 0.3789\n",
      "Epoch 7/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8891 - loss: 0.4291 - val_accuracy: 0.9212 - val_loss: 0.3865\n",
      "Epoch 8/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8854 - loss: 0.4328 - val_accuracy: 0.9212 - val_loss: 0.3028\n",
      "Epoch 9/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8777 - loss: 0.4404 - val_accuracy: 0.9212 - val_loss: 0.3392\n",
      "Epoch 10/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8723 - loss: 0.4067 - val_accuracy: 0.9212 - val_loss: 0.2472\n",
      "Epoch 11/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8773 - loss: 0.3618 - val_accuracy: 0.9212 - val_loss: 0.2150\n",
      "Epoch 12/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8859 - loss: 0.3298 - val_accuracy: 0.9212 - val_loss: 0.1890\n",
      "Epoch 13/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8893 - loss: 0.3013 - val_accuracy: 0.9325 - val_loss: 0.1572\n",
      "Epoch 14/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8864 - loss: 0.2857 - val_accuracy: 0.9375 - val_loss: 0.1532\n",
      "Epoch 15/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8966 - loss: 0.2413 - val_accuracy: 0.9388 - val_loss: 0.1394\n",
      "Epoch 16/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8951 - loss: 0.2413 - val_accuracy: 0.9463 - val_loss: 0.1267\n",
      "Epoch 17/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9139 - loss: 0.2033 - val_accuracy: 0.9575 - val_loss: 0.1129\n",
      "Epoch 18/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9134 - loss: 0.2130 - val_accuracy: 0.9538 - val_loss: 0.1108\n",
      "Epoch 19/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9333 - loss: 0.1656 - val_accuracy: 0.9650 - val_loss: 0.1048\n",
      "Epoch 20/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9246 - loss: 0.1780 - val_accuracy: 0.9638 - val_loss: 0.1098\n"
     ]
    }
   ],
   "source": [
    "# Train the model (assuming X_train and y_train are your training data)\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9571 - loss: 0.1231\n",
      "Test Accuracy: 0.9539999961853027\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"prediction.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the label encoder to a file\n",
    "with open('label_encoder_X.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders_X, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the label encoder to a file\n",
    "with open('label_encoder_Y.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder_Y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder_Y_classes.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the label encoder classes\n",
    "for col, encoder in label_encoders_X.items():\n",
    "    dump(encoder, f'label_encoder_{col}_classes.joblib')\n",
    "    \n",
    "dump(label_encoder_Y, 'label_encoder_Y_classes.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes for Proficiency level: ['High' 'Low' 'Medium']\n",
      "Classes for Preferred subjects: ['Artificial Intelligence and Machine Learning' 'Cloud Computing'\n",
      " 'CyberSecurity' 'Data Science and Analytics' 'Database Management'\n",
      " 'Devops and Systems Integration' 'IT Project Management'\n",
      " 'Network and System Administration'\n",
      " 'Software Engineering and Development' 'Web Development']\n",
      "Classes for Preferred study times: ['Afternoon' 'Evening' 'Midnight' 'Morning' 'Night']\n",
      "Classes for Goals: ['Long-term' 'Short-term']\n",
      "Classes for Curriculum structure: ['Exam' 'Knowledge']\n",
      "Classes for Available content: ['Interactive Exercises' 'Interactive exercises' 'Lectures' 'Quiz'\n",
      " 'Reading Materials' 'Tutorials']\n",
      "Classes for External factors: ['Time Constraints' 'Upcoming Exams']\n",
      "Classes for Y: ['Auditory' 'Kinesthetic' 'Visual']\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the label encoder classes\n",
    "label_encoder_X_classes = {}\n",
    "for col in ['Proficiency level', 'Preferred subjects', 'Preferred study times', 'Goals', 'Curriculum structure', 'Available content', 'External factors']:\n",
    "    label_encoder_X_classes[col] = load(f'label_encoder_{col}_classes.joblib')\n",
    "label_encoder_Y_classes = load('label_encoder_Y_classes.joblib')\n",
    "\n",
    "# Print the classes for each feature\n",
    "for col, encoder in label_encoder_X_classes.items():\n",
    "    print(f'Classes for {col}: {encoder.classes_}')\n",
    "\n",
    "print(f'Classes for Y: {label_encoder_Y_classes.classes_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes learned by the label encoder for X:\n",
      "Proficiency level:\n",
      "['High' 'Low' 'Medium']\n",
      "Preferred subjects:\n",
      "['Artificial Intelligence and Machine Learning' 'Cloud Computing'\n",
      " 'CyberSecurity' 'Data Science and Analytics' 'Database Management'\n",
      " 'Devops and Systems Integration' 'IT Project Management'\n",
      " 'Network and System Administration'\n",
      " 'Software Engineering and Development' 'Web Development']\n",
      "Preferred study times:\n",
      "['Afternoon' 'Evening' 'Midnight' 'Morning' 'Night']\n",
      "Goals:\n",
      "['Long-term' 'Short-term']\n",
      "Curriculum structure:\n",
      "['Exam' 'Knowledge']\n",
      "Available content:\n",
      "['Interactive Exercises' 'Interactive exercises' 'Lectures' 'Quiz'\n",
      " 'Reading Materials' 'Tutorials']\n",
      "External factors:\n",
      "['Time Constraints' 'Upcoming Exams']\n",
      "Classes learned by the label encoder for Y:\n",
      "['Auditory' 'Kinesthetic' 'Visual']\n"
     ]
    }
   ],
   "source": [
    "# # Check data types of preprocessed input data\n",
    "# print(\"Data types of preprocessed input:\")\n",
    "# print(preprocessed_input.dtype)\n",
    "\n",
    "# Check the classes learned by each label encoder\n",
    "print(\"Classes learned by the label encoder for X:\")\n",
    "for col, encoder in label_encoders_X.items():\n",
    "    print(col + \":\")\n",
    "    print(encoder.classes_)\n",
    "\n",
    "print(\"Classes learned by the label encoder for Y:\")\n",
    "print(label_encoder_Y.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'Software'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kavin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\kavin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\kavin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mc:\\Users\\kavin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Software'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 30\u001b[0m\n\u001b[0;32m     16\u001b[0m input_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProficiency level\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedium\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreferred subjects\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoftware\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuiz scores\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m80\u001b[39m\n\u001b[0;32m     27\u001b[0m }\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Preprocess input data for testing\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m preprocessed_input \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_encoders_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Make predictions using the trained model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(preprocessed_input)\n",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[1;34m(input_data, label_encoders_X)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, value \u001b[38;5;129;01min\u001b[39;00m input_data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m label_encoders_X:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;66;03m# Use the corresponding LabelEncoder to transform feature variables\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m         encoded_input\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlabel_encoders_X\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m# If the column is not categorical, use the value as is\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         encoded_input\u001b[38;5;241m.\u001b[39mappend(value)\n",
      "File \u001b[1;32mc:\\Users\\kavin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kavin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'Software'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to preprocess input data for testing\n",
    "def preprocess_input(input_data, label_encoders_X):\n",
    "    encoded_input = []\n",
    "    for col, value in input_data.items():\n",
    "        if col in label_encoders_X:\n",
    "            # Use the corresponding LabelEncoder to transform feature variables\n",
    "            encoded_input.append(label_encoders_X[col].transform([value])[0])\n",
    "        else:\n",
    "            # If the column is not categorical, use the value as is\n",
    "            encoded_input.append(value)\n",
    "    return np.array(encoded_input).reshape(1, -1)\n",
    "\n",
    "# Define input data for testing\n",
    "input_data = {\n",
    "    'Proficiency level': 'Medium',\n",
    "    'Preferred subjects': 'Software',\n",
    "    'Preferred study times': 'Morning',\n",
    "    'Goals': 'Short-term',\n",
    "    'Curriculum structure': 'Exam',\n",
    "    'Available content': 'Lectures',\n",
    "    'External factors': 'Time Constraints',\n",
    "    'Time spent on different types of content': 10,\n",
    "    'Completion rates': 7,\n",
    "    'Quiz scores': 80\n",
    "}\n",
    "\n",
    "# Preprocess input data for testing\n",
    "preprocessed_input = preprocess_input(input_data, label_encoders_X)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = model.predict(preprocessed_input)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "predicted_class = label_encoder_Y.classes_[predicted_class_index]\n",
    "\n",
    "print(\"Predicted Learning Style:\", predicted_class)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
