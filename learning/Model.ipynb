{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataset is in a CSV file named 'dataset.csv'\n",
    "df = pd.read_csv('F:/KA Projects/Jaye/model/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded Dataset:\n",
      "  Proficiency level Preferred subjects Preferred study times       Goals  \\\n",
      "0               Low           Software               Morning  Short-term   \n",
      "1               Low           Software               Morning  Short-term   \n",
      "2               Low           Software               Morning  Short-term   \n",
      "3               Low           Software               Morning  Short-term   \n",
      "4               Low           Software               Morning  Short-term   \n",
      "\n",
      "   Quiz scores  Completion rates  Time spent on different types of content  \\\n",
      "0            1                 1                                         1   \n",
      "1            1                 2                                         2   \n",
      "2            1                 3                                         3   \n",
      "3            1                 4                                         4   \n",
      "4            1                 5                                         5   \n",
      "\n",
      "  Curriculum structure Available content  External factors Learning style  \\\n",
      "0                 Exam          Lectures  Time Constraints         Visual   \n",
      "1            Knowledge              Quiz  Time Constraints         Visual   \n",
      "2                 Exam              Quiz  Time Constraints         Visual   \n",
      "3            Knowledge              Quiz  Time Constraints         Visual   \n",
      "4                 Exam              Quiz  Time Constraints         Visual   \n",
      "\n",
      "   Proficiency level_en  Preferred subjects_en  Preferred study times_en  \\\n",
      "0                     1                      3                         3   \n",
      "1                     1                      3                         3   \n",
      "2                     1                      3                         3   \n",
      "3                     1                      3                         3   \n",
      "4                     1                      3                         3   \n",
      "\n",
      "   Goals_en  Curriculum structure_en  Available content_en  \\\n",
      "0         3                        0                     2   \n",
      "1         3                        1                     3   \n",
      "2         3                        0                     3   \n",
      "3         3                        1                     3   \n",
      "4         3                        0                     3   \n",
      "\n",
      "   External factors_en  \n",
      "0                    0  \n",
      "1                    0  \n",
      "2                    0  \n",
      "3                    0  \n",
      "4                    0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the columns to be encoded\n",
    "categorical_cols = ['Proficiency level', 'Preferred subjects', 'Preferred study times', \n",
    "                    'Goals', 'Curriculum structure', 'Available content', 'External factors']\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoders_X = {}\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in categorical_cols:\n",
    "    label_encoders_X[col] = LabelEncoder()\n",
    "    df[col + '_en'] = label_encoders_X[col].fit_transform(df[col])\n",
    "\n",
    "# Display the first few rows of the dataset with encoded variables\n",
    "print(\"\\nEncoded Dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Now, label_encoders_X dictionary will contain LabelEncoder objects for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "selected_columns = ['Proficiency level_en', 'Preferred subjects_en', 'Preferred study times_en', 'Goals_en', 'Curriculum structure_en', 'External factors_en', 'Available content_en', 'Time spent on different types of content', 'Completion rates', 'Quiz scores']\n",
    "X = df[selected_columns]\n",
    "y = df['Learning style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode target variable using LabelEncoder\n",
    "label_encoder_Y = LabelEncoder()\n",
    "y = label_encoder_Y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\KA Projects\\Jaye\\model\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    # Input layer with 10 nodes\n",
    "    Dense(128, activation='relu', input_shape=(10,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    # Output layer with appropriate activation function\n",
    "    Dense(3, activation='softmax')  # Assuming 3 classes for the output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer labels\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,859</span> (38.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,859\u001b[0m (38.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,859</span> (38.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,859\u001b[0m (38.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6857 - loss: 3.1082 - val_accuracy: 0.9212 - val_loss: 0.3416\n",
      "Epoch 2/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 0.9069 - val_accuracy: 0.9212 - val_loss: 0.5048\n",
      "Epoch 3/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8622 - loss: 0.5825 - val_accuracy: 0.9212 - val_loss: 0.4346\n",
      "Epoch 4/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8773 - loss: 0.5319 - val_accuracy: 0.9212 - val_loss: 0.4065\n",
      "Epoch 5/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 0.5556 - val_accuracy: 0.9212 - val_loss: 0.3740\n",
      "Epoch 6/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 0.4640 - val_accuracy: 0.9212 - val_loss: 0.3524\n",
      "Epoch 7/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.4356 - val_accuracy: 0.9212 - val_loss: 0.3359\n",
      "Epoch 8/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8862 - loss: 0.4001 - val_accuracy: 0.9212 - val_loss: 0.2729\n",
      "Epoch 9/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.3891 - val_accuracy: 0.9212 - val_loss: 0.2761\n",
      "Epoch 10/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8816 - loss: 0.3706 - val_accuracy: 0.9212 - val_loss: 0.2285\n",
      "Epoch 11/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.3317 - val_accuracy: 0.9212 - val_loss: 0.1967\n",
      "Epoch 12/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.3019 - val_accuracy: 0.9212 - val_loss: 0.1599\n",
      "Epoch 13/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.2698 - val_accuracy: 0.9350 - val_loss: 0.1409\n",
      "Epoch 14/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.2457 - val_accuracy: 0.9375 - val_loss: 0.1274\n",
      "Epoch 15/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.2287 - val_accuracy: 0.9538 - val_loss: 0.1146\n",
      "Epoch 16/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2057 - val_accuracy: 0.9625 - val_loss: 0.0986\n",
      "Epoch 17/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.1740 - val_accuracy: 0.9688 - val_loss: 0.0908\n",
      "Epoch 18/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9331 - loss: 0.1857 - val_accuracy: 0.9663 - val_loss: 0.0835\n",
      "Epoch 19/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9297 - loss: 0.1522 - val_accuracy: 0.9613 - val_loss: 0.0778\n",
      "Epoch 20/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9308 - loss: 0.1538 - val_accuracy: 0.9725 - val_loss: 0.0802\n"
     ]
    }
   ],
   "source": [
    "# Train the model (assuming X_train and y_train are your training data)\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9732 - loss: 0.0961\n",
      "Test Accuracy: 0.9700000286102295\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"prediction.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the label encoder to a file\n",
    "with open('label_encoder_X.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders_X, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the label encoder to a file\n",
    "with open('label_encoder_Y.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder_Y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder_Y_classes.joblib']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the label encoder classes\n",
    "for col, encoder in label_encoders_X.items():\n",
    "    dump(encoder, f'label_encoder_{col}_classes.joblib')\n",
    "    \n",
    "dump(label_encoder_Y, 'label_encoder_Y_classes.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes for Proficiency level: ['High' 'Low' 'Medium']\n",
      "Classes for Preferred subjects: ['Database' 'Network' 'OS' 'Software']\n",
      "Classes for Preferred study times: ['Afternoon' 'Evening' 'Midnight' 'Morning' 'Night']\n",
      "Classes for Goals: ['High-term' 'Long-term' 'Low-term' 'Short-term']\n",
      "Classes for Curriculum structure: ['Exam' 'Knowledge']\n",
      "Classes for Available content: ['Interactive Exercises' 'Interactive exercises' 'Lectures' 'Quiz'\n",
      " 'Reading Materials' 'Tutorial' 'Tutorials' nan]\n",
      "Classes for External factors: ['Time Constraints' 'Upcoming Exams']\n",
      "Classes for Y: ['Auditory' 'Kinesthetic' 'Visual']\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the label encoder classes\n",
    "label_encoder_X_classes = {}\n",
    "for col in ['Proficiency level', 'Preferred subjects', 'Preferred study times', 'Goals', 'Curriculum structure', 'Available content', 'External factors']:\n",
    "    label_encoder_X_classes[col] = load(f'label_encoder_{col}_classes.joblib')\n",
    "label_encoder_Y_classes = load('label_encoder_Y_classes.joblib')\n",
    "\n",
    "# Print the classes for each feature\n",
    "for col, encoder in label_encoder_X_classes.items():\n",
    "    print(f'Classes for {col}: {encoder.classes_}')\n",
    "\n",
    "print(f'Classes for Y: {label_encoder_Y_classes.classes_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes learned by the label encoder for X:\n",
      "Proficiency level:\n",
      "['High' 'Low' 'Medium']\n",
      "Preferred subjects:\n",
      "['Database' 'Network' 'OS' 'Software']\n",
      "Preferred study times:\n",
      "['Afternoon' 'Evening' 'Midnight' 'Morning' 'Night']\n",
      "Goals:\n",
      "['High-term' 'Long-term' 'Low-term' 'Short-term']\n",
      "Curriculum structure:\n",
      "['Exam' 'Knowledge']\n",
      "Available content:\n",
      "['Interactive Exercises' 'Interactive exercises' 'Lectures' 'Quiz'\n",
      " 'Reading Materials' 'Tutorial' 'Tutorials' nan]\n",
      "External factors:\n",
      "['Time Constraints' 'Upcoming Exams']\n",
      "Classes learned by the label encoder for Y:\n",
      "['Auditory' 'Kinesthetic' 'Visual']\n"
     ]
    }
   ],
   "source": [
    "# # Check data types of preprocessed input data\n",
    "# print(\"Data types of preprocessed input:\")\n",
    "# print(preprocessed_input.dtype)\n",
    "\n",
    "# Check the classes learned by each label encoder\n",
    "print(\"Classes learned by the label encoder for X:\")\n",
    "for col, encoder in label_encoders_X.items():\n",
    "    print(col + \":\")\n",
    "    print(encoder.classes_)\n",
    "\n",
    "print(\"Classes learned by the label encoder for Y:\")\n",
    "print(label_encoder_Y.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "Predicted Learning Style: Visual\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to preprocess input data for testing\n",
    "def preprocess_input(input_data, label_encoders_X):\n",
    "    encoded_input = []\n",
    "    for col, value in input_data.items():\n",
    "        if col in label_encoders_X:\n",
    "            # Use the corresponding LabelEncoder to transform feature variables\n",
    "            encoded_input.append(label_encoders_X[col].transform([value])[0])\n",
    "        else:\n",
    "            # If the column is not categorical, use the value as is\n",
    "            encoded_input.append(value)\n",
    "    return np.array(encoded_input).reshape(1, -1)\n",
    "\n",
    "# Define input data for testing\n",
    "input_data = {\n",
    "    'Proficiency level': 'Medium',\n",
    "    'Preferred subjects': 'Software',\n",
    "    'Preferred study times': 'Morning',\n",
    "    'Goals': 'Short-term',\n",
    "    'Curriculum structure': 'Exam',\n",
    "    'Available content': 'Lectures',\n",
    "    'External factors': 'Time Constraints',\n",
    "    'Time spent on different types of content': 10,\n",
    "    'Completion rates': 7,\n",
    "    'Quiz scores': 80\n",
    "}\n",
    "\n",
    "# Preprocess input data for testing\n",
    "preprocessed_input = preprocess_input(input_data, label_encoders_X)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = model.predict(preprocessed_input)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "predicted_class = label_encoder_Y.classes_[predicted_class_index]\n",
    "\n",
    "print(\"Predicted Learning Style:\", predicted_class)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
